<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Java | 闲散记事]]></title>
  <link href="http://lvzwq.github.io/blog/categories/java/atom.xml" rel="self"/>
  <link href="http://lvzwq.github.io/"/>
  <updated>2018-11-02T16:57:00+08:00</updated>
  <id>http://lvzwq.github.io/</id>
  <author>
    <name><![CDATA[Lvzwq]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Mongodb 初使用]]></title>
    <link href="http://lvzwq.github.io/blog/2018/09/24/mongodb-chu-shi-yong/"/>
    <updated>2018-09-24T01:16:53+08:00</updated>
    <id>http://lvzwq.github.io/blog/2018/09/24/mongodb-chu-shi-yong</id>
    <content type="html"><![CDATA[<h2>Java原生API操作MongoDB</h2>

<p>本文主要介绍如何用原生api简易操作mongodb集群，</p>

<h3>加入依赖</h3>

<pre><code class="xml">&lt;dependency&gt;
    &lt;groupId&gt;org.mongodb&lt;/groupId&gt;
    &lt;artifactId&gt;mongo-java-driver&lt;/artifactId&gt;
    &lt;version&gt;3.8.2&lt;/version&gt;
&lt;/dependency&gt;
</code></pre>

<p>使用集群方式连接<code>Mongodb</code></p>

<h3>Java操作连接</h3>

<pre><code class="java">MongoCredential credential = MongoCredential.createCredential(MONGO_USRE, "admin", MONGO_PASSWD.toCharArray());
MongoClientOptions options = MongoClientOptions.builder()  
  .serverSelectionTimeout(30000)  
  .threadsAllowedToBlockForConnectionMultiplier(50)  
  .maxWaitTime(6000)  
  .sslEnabled(false)  
  .build();
MongoClient mongoClient = new MongoClient(Arrays.asList(new ServerAddress("10.50.xx.1", 27017),
                    new ServerAddress("10.50.xx.2", 27017), new ServerAddress("10.xx.3.", 27017)), credential, options);

MongoDatabase database = mongoClient.getDatabase(DBNAME);

MongoDatabase 是一个不可变类型
</code></pre>

<h3>创建文档链接</h3>

<pre><code class="java">如果根据实体类的形式插入和查询，需要实例化编解码器CodecRegistry

import static org.bson.codecs.configuration.CodecRegistries.fromProviders;  
import static org.bson.codecs.configuration.CodecRegistries.fromRegistries;

MongoDatabase database = MongoClientManager.getInstance().getDataBase("ad");
CodecRegistry pojoCodecRegistry = fromRegistries(MongoClientSettings.getDefaultCodecRegistry(),
              fromProviders(PojoCodecProvider.builder().automatic(true).build()));

# 存储结构实例类ChannelConsumeEntity
MongoCollection&lt;ChannelConsumeEntity&gt; collection = database.getCollection("channelConsume", ChannelConsumeEntity.class).withCodecRegistry(pojoCodecRegistry);

MongoCollection&lt;Document&gt; collection = database.getCollection("channelConsume", Document.class).withCodecRegistry(pojoCodecRegistry);
</code></pre>

<h3>插入及更新</h3>

<pre><code class="java">ChannelConsumeEntity entity = new ChannelConsumeEntity();  
entity.setBusinessType(value.getBusinessType());  
entity.setChannel(value.getChannel());  
entity.setDate(date);  
entity.setHour(hour);  
entity.setConsume(value.getConsume());  
entity.setVirtualConsume(value.getVirtualConsume());  
entity.setHit(value.getCount());   
collection.insertOne(entity);
# 批量插入
collection.insertMany();
</code></pre>

<h4>更新操作</h4>

<p>原生<code>SQL</code>操作修改<code>mongodb</code>
<code>
批量更新文档：
db.collection.update(
&lt;query&gt;,
&lt;update&gt;,
{
upsert: &lt;boolean&gt;,
multi: &lt;boolean&gt;,
writeConcern: &lt;document&gt;
}
)
-   query : update的查询条件，类似sql update查询内where后面的。
-   update : update的对象和一些更新的操作符（如$,$inc...）等，也可以理解为sql update查询内set后面的
-   upsert : 可选，这个参数的意思是，如果不存在update的记录，是否插入objNew,true为插入，默认是false，不插入。
-   multi : 可选，mongodb 默认是false,只更新找到的第一条记录，如果这个参数为true,就把按条件查出来多条记录全部更新。
-   writeConcern :可选，抛出异常的级别。
</code></p>

<pre><code>## db.channelConsume.update({"date": xx, "hour": xx, }, {"$set": {"consume": xx, "virtualConsume":xx}})

collection.updateOne(new Document("date", date)  
  .append("hour", hour)  
  .append("businessType", value.getBusinessType())  
  .append("categoryId", value.getCategoryId()),  
  new Document("$set", new Document("hit", entity.getHit() + value.getCount())  
  .append("consume", entity.getConsume() + value.getConsume())  
  .append("virtualConsume", entity.getVirtualConsume() + value.getVirtualConsume())));

## 更新操作
collection.updateOne(new Document("date", date)  
  .append("hour", hour)  
  .append("businessType", value.getBusinessType())  
  .append("channel", value.getChannel())  
  .append("detail.minute", minute),  
  new Document("$set", new Document("detail.$.hit", rawData.getHit() + value.getCount())  
  .append("detail.$.consume", rawData.getConsume() + value.getConsume())  
  .append("detail.$.virtualConsume", rawData.getVirtualConsume() + value.getVirtualConsume())  
 ));
</code></pre>

<h3>查询</h3>

<pre><code class="java">FindIterable&lt;ChannelConsumeEntity&gt; findIterable = collection.find(new Document("date", date)  
  .append("businessType", value.getBusinessType())  
  .append("channel", value.getChannel())  
  .append("hour", hour), ChannelConsumeEntity.class).limit(1);  

ChannelConsumeEntity entity = findIterable.first();
# 或者循环方式遍历
for (ChannelConsumeEntity entity: findIterable) {
}
</code></pre>

<h3>聚合操作</h3>

<p>管道的概念：管道在Unix和Linux中一般用于将当前命令的输出结果作为下一个命令的参数。
MongoDB的聚合管道将MongoDB文档在一个管道处理完毕后将结果传递给下一个管道处理。管道操作是可以重复的。
表达式：处理输入文档并输出。表达式是无状态的，只能用于计算当前聚合管道的文档，不能处理其它的文档。</p>

<p>这里我们介绍一下聚合框架中常用的几个操作：
-   <code>$project</code>：修改输入文档的结构。可以用来重命名、增加或删除域，也可以用于创建计算结果以及嵌套文档。
-   <code>$match</code>：用于过滤数据，只输出符合条件的文档。$match使用MongoDB的标准查询操作。
-   <code>$limit</code>：用来限制MongoDB聚合管道返回的文档数。
-   <code>$skip</code>：在聚合管道中跳过指定数量的文档，并返回余下的文档。
-   <code>$unwind</code>：将文档中的某一个数组类型字段拆分成多条，每条包含数组中的一个值。
-   <code>$group</code>：将集合中的文档分组，可用于统计结果。
-   <code>$sort</code>：将输入文档排序后输出。
-   <code>$geoNear</code>：输出接近某一地理位置的有序文档。
```</p>

<h1>取出20181001号按照categoryId进行聚合的数据，类似于mysql如下</h1>

<h1>select SUM(payOrders) AS payOrderSum, SUM(payPrice) AS payPrice, categoryId, date FROM categoryOrder</h1>

<p> WHERE date = 20181001 group by categoryId order by payPrice DESC;</p>

<h1>mongodb sql语法</h1>

<p>db.categoryOrder.aggregate({&ldquo;$match&rdquo;: {&ldquo;date&rdquo;: 20181001}}, {&ldquo;$group&rdquo;:{&ldquo;_id&rdquo;:{&ldquo;categoryId&rdquo;: &ldquo;$categoryId&rdquo;}, &ldquo;payOrderSum&rdquo;:{&ldquo;$sum&rdquo;:&ldquo;$payOrders&rdquo;}, &ldquo;payPrice&rdquo;:{&ldquo;$sum&rdquo;: &ldquo;$payPrice&rdquo;}}}, {&ldquo;$sort&rdquo;: {&ldquo;payPrice&rdquo;: -1}})
```</p>

<pre><code class="java">MongoCollection&lt;ChannelConsumeEntity&gt; collection = database.getCollection("channelConsume", ChannelConsumeEntity.class).withCodecRegistry(pojoCodecRegistry);  

List&lt;BasicDBObject&gt; pipeLine = new ArrayList&lt;&gt;(3);  
BasicDBObject match = new BasicDBObject("$match", new Document("date", date));  
BasicDBObject group = new BasicDBObject("$group", new Document("_id", new Document("channel", "$channel").append("businessType", "$businessType"))  
  .append("consume", new Document("$sum", "$consume"))  
  .append("virtualConsume", new Document("$sum", "$virtualConsume"))  
  .append("hit", new Document("$sum", "$hit")));  
BasicDBObject sort = new BasicDBObject("$sort", new Document("hit", -1));  

pipeLine.add(match);  
pipeLine.add(group);  
pipeLine.add(sort);  
AggregateIterable&lt;Document&gt; aggregateIterable = collection.aggregate(pipeLine, Document.class);
</code></pre>

<h3>参考</h3>

<ul>
<li><a href="http://rosslawley.co.uk/mongodb-pojo-support/">MongoDB POJO Support</a></li>
<li><a href="http://www.runoob.com/mongodb/mongodb-update.html">菜鸟文档 - MongoDB 更新文档</a></li>
<li><a href="http://www.runoob.com/mongodb/mongodb-aggregate.html">菜鸟文档 - MongoDB聚合</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Storm Trident 批处理模式学习]]></title>
    <link href="http://lvzwq.github.io/blog/2018/09/14/storm-trident-xue-xi/"/>
    <updated>2018-09-14T12:22:02+08:00</updated>
    <id>http://lvzwq.github.io/blog/2018/09/14/storm-trident-xue-xi</id>
    <content type="html"><![CDATA[<!-- more -->


<pre><code class="java">/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.storm.trident.topology;

import org.apache.storm.Config;
import org.apache.storm.spout.SpoutOutputCollector;
import org.apache.storm.task.TopologyContext;
import org.apache.storm.topology.OutputFieldsDeclarer;
import org.apache.storm.topology.base.BaseRichSpout;
import org.apache.storm.trident.spout.ITridentSpout;
import org.apache.storm.trident.topology.state.TransactionalState;
import org.apache.storm.tuple.Fields;
import org.apache.storm.tuple.Values;
import org.apache.storm.utils.WindowedTimeThrottler;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import java.util.ArrayList;
import java.util.HashMap;
import java.util.List;
import java.util.Map;
import java.util.Map.Entry;
import java.util.TreeMap;

public class MasterBatchCoordinator extends BaseRichSpout {
    public static final Logger LOG = LoggerFactory.getLogger(MasterBatchCoordinator.class);

    public static final long INIT_TXID = 1L;


    public static final String BATCH_STREAM_ID = "$batch";
    public static final String COMMIT_STREAM_ID = "$commit";
    public static final String SUCCESS_STREAM_ID = "$success";

    private static final String CURRENT_TX = "currtx";
    private static final String CURRENT_ATTEMPTS = "currattempts";

    private List&lt;TransactionalState&gt; _states = new ArrayList();

    TreeMap&lt;Long, TransactionStatus&gt; _activeTx = new TreeMap&lt;Long, TransactionStatus&gt;();
    TreeMap&lt;Long, Integer&gt; _attemptIds;

    private SpoutOutputCollector _collector;
    Long _currTransaction;

    // 默认值为1, 取配置的TOPOLOGY_MAX_SPOUT_PENDING
    int _maxTransactionActive;

    List&lt;ITridentSpout.BatchCoordinator&gt; _coordinators = new ArrayList();


    List&lt;String&gt; _managedSpoutIds;
    List&lt;ITridentSpout&gt; _spouts;
    WindowedTimeThrottler _throttler;

    boolean _active = true;

    public MasterBatchCoordinator(List&lt;String&gt; spoutIds, List&lt;ITridentSpout&gt; spouts) {
        if(spoutIds.isEmpty()) {
            throw new IllegalArgumentException("Must manage at least one spout");
        }
        _managedSpoutIds = spoutIds;
        _spouts = spouts;
        LOG.debug("Created {}", this);
    }

    public List&lt;String&gt; getManagedSpoutIds(){
        return _managedSpoutIds;
    }

    @Override
    public void activate() {
        _active = true;
    }

    @Override
    public void deactivate() {
        _active = false;
    }

    @Override
    public void open(Map conf, TopologyContext context, SpoutOutputCollector collector) {
        _throttler = new WindowedTimeThrottler((Number)conf.get(Config.TOPOLOGY_TRIDENT_BATCH_EMIT_INTERVAL_MILLIS), 1);
        for(String spoutId: _managedSpoutIds) {
            _states.add(TransactionalState.newCoordinatorState(conf, spoutId));
        }
        _currTransaction = getStoredCurrTransaction();

        _collector = collector;
        Number active = (Number) conf.get(Config.TOPOLOGY_MAX_SPOUT_PENDING);
        if(active==null) {
            _maxTransactionActive = 1;
        } else {
            _maxTransactionActive = active.intValue();
        }
        _attemptIds = getStoredCurrAttempts(_currTransaction, _maxTransactionActive);


        for(int i=0; i&lt;_spouts.size(); i++) {
            String txId = _managedSpoutIds.get(i);
            _coordinators.add(_spouts.get(i).getCoordinator(txId, conf, context));
        }
        LOG.debug("Opened {}", this);
    }

    @Override
    public void close() {
        for(TransactionalState state: _states) {
            state.close();
        }
        LOG.debug("Closed {}", this);
    }

    @Override
    public void nextTuple() {
        sync();
    }

    @Override
    public void ack(Object msgId) {
        TransactionAttempt tx = (TransactionAttempt) msgId;
        TransactionStatus status = _activeTx.get(tx.getTransactionId());
        LOG.debug("Ack. [tx_attempt = {}], [tx_status = {}], [{}]", tx, status, this);
        if(status!=null &amp;&amp; tx.equals(status.attempt)) {
            if(status.status==AttemptStatus.PROCESSING) {
                status.status = AttemptStatus.PROCESSED;
                LOG.debug("Changed status. [tx_attempt = {}] [tx_status = {}]", tx, status);
            } else if(status.status==AttemptStatus.COMMITTING) {
                _activeTx.remove(tx.getTransactionId());
                _attemptIds.remove(tx.getTransactionId());
                _collector.emit(SUCCESS_STREAM_ID, new Values(tx));
                _currTransaction = nextTransactionId(tx.getTransactionId());
                for(TransactionalState state: _states) {
                    state.setData(CURRENT_TX, _currTransaction);                    
                }
                LOG.debug("Emitted on [stream = {}], [tx_attempt = {}], [tx_status = {}], [{}]", SUCCESS_STREAM_ID, tx, status, this);
            }
            sync();
        }
    }

    @Override
    public void fail(Object msgId) {
        TransactionAttempt tx = (TransactionAttempt) msgId;
        TransactionStatus stored = _activeTx.remove(tx.getTransactionId());
        LOG.debug("Fail. [tx_attempt = {}], [tx_status = {}], [{}]", tx, stored, this);
        if(stored!=null &amp;&amp; tx.equals(stored.attempt)) {
            _activeTx.tailMap(tx.getTransactionId()).clear();
            sync();
        }
    }

    @Override
    public void declareOutputFields(OutputFieldsDeclarer declarer) {
        // in partitioned example, in case an emitter task receives a later transaction than it's emitted so far,
        // when it sees the earlier txid it should know to emit nothing
        declarer.declareStream(BATCH_STREAM_ID, new Fields("tx"));
        declarer.declareStream(COMMIT_STREAM_ID, new Fields("tx"));
        declarer.declareStream(SUCCESS_STREAM_ID, new Fields("tx"));
    }

    private void sync() {
        // note that sometimes the tuples active may be less than max_spout_pending, e.g.
        // max_spout_pending = 3
        // tx 1, 2, 3 active, tx 2 is acked. there won't be a commit for tx 2 (because tx 1 isn't committed yet),
        // and there won't be a batch for tx 4 because there's max_spout_pending tx active
        TransactionStatus maybeCommit = _activeTx.get(_currTransaction);
        if(maybeCommit!=null &amp;&amp; maybeCommit.status == AttemptStatus.PROCESSED) {
            maybeCommit.status = AttemptStatus.COMMITTING;
            _collector.emit(COMMIT_STREAM_ID, new Values(maybeCommit.attempt), maybeCommit.attempt);
            LOG.debug("Emitted on [stream = {}], [tx_status = {}], [{}]", COMMIT_STREAM_ID, maybeCommit, this);
        }

        if(_active) {
            if(_activeTx.size() &lt; _maxTransactionActive) {
                Long curr = _currTransaction;
                for(int i=0; i&lt;_maxTransactionActive; i++) {
                    if(!_activeTx.containsKey(curr) &amp;&amp; isReady(curr)) {
                        // by using a monotonically increasing attempt id, downstream tasks
                        // can be memory efficient by clearing out state for old attempts
                        // as soon as they see a higher attempt id for a transaction
                        Integer attemptId = _attemptIds.get(curr);
                        if(attemptId==null) {
                            attemptId = 0;
                        } else {
                            attemptId++;
                        }
                        _attemptIds.put(curr, attemptId);
                        for(TransactionalState state: _states) {
                            state.setData(CURRENT_ATTEMPTS, _attemptIds);
                        }

                        TransactionAttempt attempt = new TransactionAttempt(curr, attemptId);
                        final TransactionStatus newTransactionStatus = new TransactionStatus(attempt);
                        _activeTx.put(curr, newTransactionStatus);
                        _collector.emit(BATCH_STREAM_ID, new Values(attempt), attempt);
                        LOG.debug("Emitted on [stream = {}], [tx_attempt = {}], [tx_status = {}], [{}]", BATCH_STREAM_ID, attempt, newTransactionStatus, this);
                        _throttler.markEvent();
                    }
                    curr = nextTransactionId(curr);
                }
            }
        }
    }

    private boolean isReady(long txid) {
        if(_throttler.isThrottled()) return false;
        //TODO: make this strategy configurable?... right now it goes if anyone is ready
        for(ITridentSpout.BatchCoordinator coord: _coordinators) {
            if(coord.isReady(txid)) return true;
        }
        return false;
    }

    @Override
    public Map&lt;String, Object&gt; getComponentConfiguration() {
        Config ret = new Config();
        ret.setMaxTaskParallelism(1);
        ret.registerSerialization(TransactionAttempt.class);
        return ret;
    }

    private static enum AttemptStatus {
        PROCESSING,
        PROCESSED,
        COMMITTING
    }

    private static class TransactionStatus {
        TransactionAttempt attempt;
        AttemptStatus status;

        public TransactionStatus(TransactionAttempt attempt) {
            this.attempt = attempt;
            this.status = AttemptStatus.PROCESSING;
        }

        @Override
        public String toString() {
            return attempt.toString() + " &lt;" + status.toString() + "&gt;";
        }        
    }


    private Long nextTransactionId(Long id) {
        return id + 1;
    }  

    private Long getStoredCurrTransaction() {
        Long ret = INIT_TXID;
        for(TransactionalState state: _states) {
            Long curr = (Long) state.getData(CURRENT_TX);
            if(curr!=null &amp;&amp; curr.compareTo(ret) &gt; 0) {
                ret = curr;
            }
        }
        return ret;
    }

    private TreeMap&lt;Long, Integer&gt; getStoredCurrAttempts(long currTransaction, int maxBatches) {
        TreeMap&lt;Long, Integer&gt; ret = new TreeMap&lt;Long, Integer&gt;();
        for(TransactionalState state: _states) {
            Map&lt;Object, Number&gt; attempts = (Map) state.getData(CURRENT_ATTEMPTS);
            if(attempts==null) attempts = new HashMap();
            for(Entry&lt;Object, Number&gt; e: attempts.entrySet()) {
                // this is because json doesn't allow numbers as keys...
                // TODO: replace json with a better form of encoding
                Number txidObj;
                if(e.getKey() instanceof String) {
                    txidObj = Long.parseLong((String) e.getKey());
                } else {
                    txidObj = (Number) e.getKey();
                }
                long txid = ((Number) txidObj).longValue();
                int attemptId = ((Number) e.getValue()).intValue();
                Integer curr = ret.get(txid);
                if(curr==null || attemptId &gt; curr) {
                    ret.put(txid, attemptId);
                }                
            }
        }
        ret.headMap(currTransaction).clear();
        ret.tailMap(currTransaction + maxBatches - 1).clear();
        return ret;
    }

    @Override
    public String toString() {
        return "MasterBatchCoordinator{" +
                "_states=" + _states +
                ", _activeTx=" + _activeTx +
                ", _attemptIds=" + _attemptIds +
                ", _collector=" + _collector +
                ", _currTransaction=" + _currTransaction +
                ", _maxTransactionActive=" + _maxTransactionActive +
                ", _coordinators=" + _coordinators +
                ", _managedSpoutIds=" + _managedSpoutIds +
                ", _spouts=" + _spouts +
                ", _throttler=" + _throttler +
                ", _active=" + _active +
                "}";
    }
}
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Java内存区域与垃圾收集器]]></title>
    <link href="http://lvzwq.github.io/blog/2017/08/17/javanei-cun-qu-yu-yu-la-ji-shou-ji-qi/"/>
    <updated>2017-08-17T00:11:08+08:00</updated>
    <id>http://lvzwq.github.io/blog/2017/08/17/javanei-cun-qu-yu-yu-la-ji-shou-ji-qi</id>
    <content type="html"><![CDATA[<h2>运行程序时数据区域</h2>

<blockquote><p>Java虚拟机在执行Java程序的过程中会把它所管理的内存划分为若干个不同的数据区域。</p></blockquote>

<!-- more -->


<p><img src="http://zhangwenqiang.com.cn/%E5%86%85%E5%AD%98.png" alt="http://zhangwenqiang.com.cn/%E5%86%85%E5%AD%98.png" /></p>

<h3>程序计数器(Program Counter Register)</h3>

<p>程序计数器是一块较小的内存空间，他可以看做是当前线程所执行的的字节码的行号指示器。</p>

<h3>Java 虚拟机栈</h3>

<p>线程私有，生命周期与线程相同。每一个方法在执行的同时都会创建一个栈帧(Stack Frame)用于存储局部变量表、操作数栈、动态链接、方法出口等信息。每一个方法从调用到直至执行完成的过程，就对应着一个栈帧在虚拟机栈中入栈和出栈的过程。</p>

<h3>本地方法栈</h3>

<p>本地方法栈与虚拟机栈所发挥的作用是非常相似的，他们之间的区别不过是虚拟机栈为虚拟机执行Java方法(字节码)服务，而本地方法栈则为虚拟机使用的Native方法服务。</p>

<h3>Java堆</h3>

<p>对于大多数应用而言，Java堆是Java虚拟机所管理的内存中最大的一块，在虚拟机启动时创建，是所有线程共享的一块内存区域，此内存区域的作用就是存放对象实例，几乎所有的对象实例都在这里分配内存。Java堆是垃圾回收器管理的主要区域，也被成为GC堆。</p>

<h3>方法区</h3>

<p>方法区是线程共享的内存区域，用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译的代码等数据。</p>

<h3>运行时常量池(Runtime Constants Pool)</h3>

<p>运行时常量池是方法区的一部分。</p>

<h3>对象创建</h3>

<blockquote><p>虚拟机遇到一条new指令是，首先去检查这个指令额参数是否能在常量池中定位到一个类的符号引用，并且检查这个符号引用代表的类是否已经被加载、解析和初始化过。如果没有则必须执行相应的类加载过程。
在类加载检查通过后，接下来虚拟机将为新生对象分配内存。对象所需的内存大小在类加载完成后便可完全确定，为对象分配空间的任务等同于把一块确定大小的内存空间从Java堆中划分出来。</p></blockquote>

<h3>java堆内存分配方式</h3>

<ul>
<li>指针碰撞：假设java堆中内存是绝对规整的</li>
<li>空闲列表:  虚拟机维护一个列表，记录那些内存块是可用的</li>
</ul>


<p>java堆内存是否规整由所采用的垃圾收集器是否带有压缩整理功能决定。因此在使用Serial、ParNew等带有Compact过程的收集器时，系统采用的分配算法是指针碰撞，而使用CMS这种基于Mark-Sweep算法的收集器，通常采用空闲列表。</p>

<h2>垃圾收集器与内存分配策略</h2>

<h3>判断对象是否存活</h3>

<ul>
<li><p>引用计数算法：给对象添加一个引用计数器，每当有一个地方引用它时，计数器就加1，当引用失效时，计数器值就减1，在任意时刻计数器为0的对象就是不可能再被使用的。目前主流的虚拟机里并没有选用引用计数算法来管理内存，其中最主要的原因是它很难解决对象之间循环引用的问题。</p></li>
<li><p>可达性分析算法：通过一系列的称为”GC Roots“的对象作为起始点，从这些节点开始向下搜索，搜索所走过的路径被称为引用链，当一个对象到GC Roots没有任何引用链相连时，则称为此对象是不可用的，它们到GC Roots是不可达的，所以它们将会被判定为是可回收的对象。</p></li>
</ul>


<p>在JDK1.2后，Java对引用的概念进行了扩充，将引用划分为强引用、软引用、弱引用、虚引用，这4种引用强度逐渐减弱。</p>

<h3>垃圾收集算法</h3>

<ul>
<li><p><strong>标记-清除算法(Mark-Sweep)</strong>： 算法分为标记和清除两个阶段，是最基础的收集算法。首先标记处所有需要回收的对象，在标记完成后统一回收所有被标记的对象。
主要的不足有两个:
效率问题，标记和清除两个过程的效率都不高；
空间问题，标记清除之后会产生大量不连续的内存碎片，空间碎片太多可能会导致以后再程序运行过程中需要分配较大对象时，无法找到足够连续内存而不得不提前出发另一次的垃圾回收动作。</p></li>
<li><p><strong>复制算法</strong>: 为了解决效率问题，将可用内存按容量大小分为大小相同的两块，每次只使用其中的一块。当这一块的内存用完了，就将还存活的对象复制到另外一块上面，然后再把已使用的内存空间一次清理掉。这样使得每次都是对整个半区进行内存回收，内存分配是也就不用考虑内存碎片等复杂情况，只要移动堆顶指针，按顺序分配内存即可，实现简单，运行高效。只是这种算法的代价是将内存缩小为了原来的一半。</p></li>
</ul>


<blockquote><p>商业虚拟机都采用这种收集算法来回收新生代，因为新生代中的对象98%是朝生夕死的，所以并不需要按照1:1的比例来划分内存空间，而是将内存分为一块较大的Eden空间和两块较小的Suvivor空间，每次使用Eden空间和其中一块Survivor空间。当回收时，将Eden空间和Survivor空间中还存活的对象一次性地复制到另外一块Survivor空间上，最后清理掉Eden空间和Survivor空间。HotSpot虚拟机默认的Eden和Survivor的大小比例是8:1.
当Survivor空间不够用时，需要依赖其他内存(这里指老年代)进行分配担保。</p></blockquote>

<ul>
<li><p><strong>标记-整理算法</strong>： 复制收集算法在对象存活率较高时就要进行较多的复制操作，效率将会降低。更为关键的是，如果不想浪费50%的空间，就需要有额外的空间进行担保，以应对被使用的内存中所有对象都100%存活的极端情况，所以老年代一般不能直接选用这种算法。
标记整理算法的标记过程仍然与“标记-清除”算法一样，但后续步骤不是直接对可回收对象进行整理，而是让所有存活的对象都向一段移动，然后直接清理掉端边界以外的内存。</p></li>
<li><p><strong>分代收集算法</strong>：根据对象存活周期的不同将内存划分为几块。一般是把Java堆分为新生代和老年代，这样可以根据各个年代的特点采用最适合的收集算法。
在新生代中，每次垃圾收集时都发现有大批对象死去，只有少量存活，那就使用复制算法，只需要付出少量存活对象的复制成本就可以完成收集。而老年代中因为对象存活率高、没有额外空间对它进行分配担保，就必须使用“标记-清除”或者“标记-整理”算法来进行收集。</p></li>
</ul>


<h2>垃圾收集器</h2>

<p><img src="http://zhangwenqiang.com.cn/%E5%88%86%E5%8C%BA.png" alt="http://zhangwenqiang.com.cn/%E5%88%86%E5%8C%BA.png" /></p>

<h3>Serial收集器</h3>

<blockquote><p>Serial收集器是最基本、发展历史最悠久的收集器，是一个单线程的收集器。只会使用一个CPU或一条收集线程去完成垃圾收集工作，在进行垃圾收集时，必须暂停其他所有的工作线程，直到它收集结束。</p></blockquote>

<h3>ParNew收集器</h3>

<blockquote><p>ParNew收集器是Serial收集器的多线程版本，除了使用多条线程进行垃圾收集之外，其余行为基本与Serial收集器完全一样。</p></blockquote>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[SpringBoot学习笔记一]]></title>
    <link href="http://lvzwq.github.io/blog/2017/08/17/springboxue-xi-bi-ji-1/"/>
    <updated>2017-08-17T00:09:28+08:00</updated>
    <id>http://lvzwq.github.io/blog/2017/08/17/springboxue-xi-bi-ji-1</id>
    <content type="html"><![CDATA[<h2>特点</h2>

<ul>
<li>Create stand-alone Spring applications</li>
<li>Embed Tomcat, Jetty or Undertow directly (no need to deploy WAR files)</li>
<li>Provide opinionated &lsquo;starter&rsquo; POMs to simplify your Maven configuration</li>
<li>Automatically configure Spring whenever possible</li>
<li>Provide production-ready features such as metrics, health checks and externalized configuration</li>
<li>Absolutely no code generation and no requirement for XML configuration</li>
</ul>


<!-- more -->


<p>SpringBoot应用Maven依赖加入
```
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-parent</artifactId>
    <version>1.5.6.RELEASE</version>
    <scope>import</scope>
    <type>pom</type>
</dependency></p>

<p><dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter</artifactId>
    <version>1.5.6.RELEASE</version>
</dependency>
```</p>

<p>如果要web环境，只需要加入web的starter
<code>
&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
    &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;
    &lt;version&gt;1.5.6.RELEASE&lt;/version&gt;
&lt;/dependency&gt;
</code></p>

<p>SpringBoot应用建立
```
@Slf4j
@SpringBootApplication
public class Application {</p>

<pre><code>public static void main(String[] args) {
    SpringApplication app = new SpringApplication(Application.class);
    app.run(args);
    //或者直接调用run方法
   //SpringApplication.run(Application.class, args);
}     
</code></pre>

<p>}
```
注解@SpringBootApplication是@Configuration、@EnableAutoConfiguration 和@ComponentScan的简化方式。</p>

<h3>初始化</h3>

<p>创建SpringApplication对象实例，构造器中会调用初始化操作
<code>java
@SuppressWarnings({ "unchecked", "rawtypes" })
private void initialize(Object[] sources) {
   if (sources != null &amp;&amp; sources.length &gt; 0) {
      this.sources.addAll(Arrays.asList(sources));
   }
    // 判断是否是web程序(javax.servlet.Servlet和org.springframework.web.context.ConfigurableWebApplicationContext都必须在类加载器中存在)，
    // 并设置到webEnvironment属性中
   this.webEnvironment = deduceWebEnvironment();
   // 从spring.factories文件中找出key为ApplicationContextInitializer的类并实例化后设置到SpringApplication的initializers属性中。
   //这个过程也就是找出所有的应用程序初始化器
   setInitializers((Collection) getSpringFactoriesInstances(ApplicationContextInitializer.class));
    // 从spring.factories文件中找出key为ApplicationListener的类并实例化后设置到SpringApplication的listeners属性中。
    //这个过程就是找出所有的应用程序事件监听器
   setListeners((Collection) getSpringFactoriesInstances(ApplicationListener.class));
   // 找出main类，这里是Application类
   this.mainApplicationClass = deduceMainApplicationClass();
}
</code></p>

<p>判断是否是WEB环境
<code>Java
private boolean deduceWebEnvironment() {
   for (String className : WEB_ENVIRONMENT_CLASSES) {
      if (!ClassUtils.isPresent(className, null)) {
         return false;
      }
   }
   return true;
}
</code></p>

<p>ApplicationContextInitializer，应用程序初始化器，做一些初始化的工作：
<code>Java
public interface ApplicationContextInitializer&lt;C extends ConfigurableApplicationContext&gt; {
    void initialize(C applicationContext);
}
</code></p>

<p>ApplicationListener，应用程序事件(ApplicationEvent)监听器：
<code>java
public interface ApplicationListener&lt;E extends ApplicationEvent&gt; extends EventListener {
    void onApplicationEvent(E event);
}
</code></p>

<p>应用程序事件(ApplicationEvent)监听器有一下几种:(org.springframework.boot.context.event)
<code>
ApplicationStartingEvent(应用程序启动事件)
ApplicationEnvironmentPreparedEvent(环境准备事件)
ApplicationPreparedEvent(准备事件)
ApplicationReadyEvent(启动事件)
ApplicationFailedEvent(失败事件)
</code></p>

<p>默认情况下，initialize方法从spring.factories文件中找出的key为ApplicationContextInitializer的类有：
<code>
org.springframework.boot.context.config.DelegatingApplicationContextInitializer
org.springframework.boot.context.ContextIdApplicationContextInitializer
org.springframework.boot.context.ConfigurationWarningsApplicationContextInitializer
org.springframework.boot.context.web.ServerPortInfoApplicationContextInitializer
org.springframework.boot.autoconfigure.logging.AutoConfigurationReportLoggingInitializer
</code></p>

<p>key为ApplicationListener的有：
<code>
org.springframework.boot.context.config.AnsiOutputApplicationListener
org.springframework.boot.context.config.ConfigFileApplicationListener
org.springframework.boot.logging.LoggingApplicationListener
org.springframework.boot.logging.ClasspathLoggingApplicationListener
org.springframework.boot.autoconfigure.BackgroundPreinitializer
org.springframework.boot.context.config.DelegatingApplicationListener
org.springframework.boot.builder.ParentContextCloserApplicationListener
org.springframework.boot.context.FileEncodingApplicationListener
org.springframework.boot.liquibase.LiquibaseServiceLocatorApplicationListener
</code></p>

<p>分析run方法之前，先看一下SpringApplication中的一些事件和监听器概念</p>

<blockquote><p>首先是SpringApplicationRunListeners类和SpringApplicationRunListener类的介绍。</p></blockquote>

<p>SpringApplicationRunListeners内部持有SpringApplicationRunListener集合和1个Log日志类。用于SpringApplicationRunListener监听器的批量执行。</p>

<p>SpringApplicationRunListener看名字也知道用于监听SpringApplication的run方法的执行。</p>

<pre><code>
started(run方法执行的时候立马执行；对应事件的类型是ApplicationStartingEvent)

environmentPrepared(ApplicationContext创建之前并且环境信息准备好的时候调用；对应事件的类型是ApplicationEnvironmentPreparedEvent)

contextPrepared(ApplicationContext创建好并且在source加载之前调用一次；没有具体的对应事件)

contextLoaded(ApplicationContext创建并加载之后并在refresh之前调用；对应事件的类型是ApplicationPreparedEvent)

finished(run方法结束之前调用；对应事件的类型是ApplicationReadyEvent或ApplicationFailedEvent)
</code></pre>

<h3>启动</h3>

<pre><code>/**
 * Run the Spring application, creating and refreshing a new
 * {@link ApplicationContext}.
 * @param args the application arguments (usually passed from a Java main method)
 * @return a running {@link ApplicationContext}
 */
public ConfigurableApplicationContext run(String... args) {
   StopWatch stopWatch = new StopWatch(); // 构造一个任务执行观察器
   stopWatch.start();   // 开始执行，记录开始时间
   ConfigurableApplicationContext context = null;
   FailureAnalyzers analyzers = null;
   configureHeadlessProperty();
   //加载META-INF/spring.factories, 获取SpringApplicationRunListeners，内部只有一个EventPublishingRunListener
   SpringApplicationRunListeners listeners = getRunListeners(args);  
   //这里接受ApplicationStartingEvent事件的listener会执行相应的操作
   listeners.starting();
   try {
      // 构造一个应用程序参数持有类
      ApplicationArguments applicationArguments = new DefaultApplicationArguments(args);
      //创建应用程序的环境信息。如果是web程序，创建StandardServletEnvironment；否则，创建StandardEnvironment
      //执行ApplicationEnvironmentPreparedEvent事件
      ConfigurableEnvironment environment = prepareEnvironment(listeners, applicationArguments);
      Banner printedBanner = printBanner(environment);
       // 创建Spring容器
      context = createApplicationContext();
      analyzers = new FailureAnalyzers(context);
      prepareContext(context, environment, listeners, applicationArguments, printedBanner);
      // Spring容器的刷新
      refreshContext(context);
      //// 调用Spring容器中的ApplicationRunner和CommandLineRunner接口的实现类
      afterRefresh(context, applicationArguments);
      // 广播出ApplicationReadyEvent事件给相应的监听器执行
      listeners.finished(context, null);
      stopWatch.stop();
      if (this.logStartupInfo) {
         new StartupInfoLogger(this.mainApplicationClass).logStarted(getApplicationLog(), stopWatch);
      }
       // 返回Spring容器
      return context;
   }
   catch (Throwable ex) {
      handleRunFailure(context, listeners, analyzers, ex);
      throw new IllegalStateException(ex);
   }
}
</code></pre>

<p>创建容器中
Spring 5 - Spring webflux 是一个新的非堵塞函数式 Reactive Web 框架，可以用来建立异步的，非阻塞，事件驱动的服务，并且扩展性非常好</p>

<h3>应用Application启动过程</h3>

<p>创建容器阶段
<code>java
protected ConfigurableApplicationContext createApplicationContext() {
   Class&lt;?&gt; contextClass = this.applicationContextClass;
    //判断是WEB容器还是非WEB容器
   if (contextClass == null) {
      try {
         contextClass = Class.forName(this.webEnvironment
               ? DEFAULT_WEB_CONTEXT_CLASS : DEFAULT_CONTEXT_CLASS);
      }
      catch (ClassNotFoundException ex) {
         throw new IllegalStateException(
               "Unable create a default ApplicationContext, "
                     + "please specify an ApplicationContextClass",
               ex);
      }
   }
   return (ConfigurableApplicationContext) BeanUtils.instantiate(contextClass);
}
</code></p>

<p>容器准备阶段
```
private void prepareContext(ConfigurableApplicationContext context,
      ConfigurableEnvironment environment, SpringApplicationRunListeners listeners,
      ApplicationArguments applicationArguments, Banner printedBanner) {
   // 设置Spring容器的环境信息
   context.setEnvironment(environment);
    // 回调方法，Spring容器创建之后做一些额外的事
   postProcessApplicationContext(context);
   // SpringApplication的的初始化器开始工作,批量执行ApplicationContextInitializer.initialize()方法
   applyInitializers(context);</p>

<p>   listeners.contextPrepared(context);  //没对应具体的事件，EventPublishingRunListener.contextPrepared()不执行任何操作
   if (this.logStartupInfo) {
      logStartupInfo(context.getParent() == null);
      logStartupProfileInfo(context);
   }</p>

<p>   // Add boot specific singleton beans
   context.getBeanFactory().registerSingleton(&ldquo;springApplicationArguments&rdquo;, applicationArguments);
   if (printedBanner != null) {
      context.getBeanFactory().registerSingleton(&ldquo;springBootBanner&rdquo;, printedBanner);
   }</p>

<p>   // Load the sources
   Set<Object> sources = getSources();
   Assert.notEmpty(sources, &ldquo;Sources must not be empty&rdquo;);
   //加载bean到容器context中
   load(context, sources.toArray(new Object[sources.size()]));
   //执行ApplicationPreparedEvent
   listeners.contextLoaded(context);
}</p>

<h2>其中</h2>

<p>/<em>*
 * Apply any relevant post processing the {@link ApplicationContext}. Subclasses can
 * apply additional processing as required.
 * @param context the application context
 </em>/
protected void postProcessApplicationContext(ConfigurableApplicationContext context) {
   if (this.beanNameGenerator != null) {
      context.getBeanFactory().registerSingleton(AnnotationConfigUtils.CONFIGURATION_BEAN_NAME_GENERATOR, this.beanNameGenerator);
   }
   // 如果SpringApplication设置了资源加载器，设置到Spring容器中
   if (this.resourceLoader != null) {
      if (context instanceof GenericApplicationContext) {
         ((GenericApplicationContext) context).setResourceLoader(this.resourceLoader);
      }
      if (context instanceof DefaultResourceLoader) {
         ((DefaultResourceLoader) context).setClassLoader(this.resourceLoader.getClassLoader());
      }
   }
}
```</p>

<p>容器刷新阶段
```
private void refreshContext(ConfigurableApplicationContext context) {
   refresh(context);
   if (this.registerShutdownHook) {
      try {
         context.registerShutdownHook();
      }
      catch (AccessControlException ex) {
         // Not allowed in some environments.
      }
   }
}</p>

<h2>执行applicationContext.refresh()方法</h2>

<p>protected void refresh(ApplicationContext applicationContext) {
   Assert.isInstanceOf(AbstractApplicationContext.class, applicationContext);
   ((AbstractApplicationContext) applicationContext).refresh();
}</p>

<h2>spring-context包内的applicationContext.refresh()方法</h2>

<p>public void refresh() throws BeansException, IllegalStateException {
    Object var1 = this.startupShutdownMonitor;
    synchronized(this.startupShutdownMonitor) {
        this.prepareRefresh();
        ConfigurableListableBeanFactory beanFactory = this.obtainFreshBeanFactory();
        this.prepareBeanFactory(beanFactory);</p>

<pre><code>    try {
        this.postProcessBeanFactory(beanFactory);
        this.invokeBeanFactoryPostProcessors(beanFactory);
        this.registerBeanPostProcessors(beanFactory);
        this.initMessageSource();
        this.initApplicationEventMulticaster();
        this.onRefresh();
        this.registerListeners();
        this.finishBeanFactoryInitialization(beanFactory);
        this.finishRefresh();
    } catch (BeansException var9) {
        if(this.logger.isWarnEnabled()) {
            this.logger.warn("Exception encountered during context initialization - cancelling refresh attempt: " + var9);
        }

        this.destroyBeans();
        this.cancelRefresh(var9);
        throw var9;
    } finally {
        this.resetCommonCaches();
    }

}
</code></pre>

<p>}
```</p>

<p>容器创建完成之后
```
/<em>*
 * Called after the context has been refreshed.
 * @param context the application context
 * @param args the application arguments
 </em>/
protected void afterRefresh(ConfigurableApplicationContext context, ApplicationArguments args) {
   callRunners(context, args);
}</p>

<p>private void callRunners(ApplicationContext context, ApplicationArguments args) {
   List<Object> runners = new ArrayList<Object>();
   runners.addAll(context.getBeansOfType(ApplicationRunner.class).values());
   runners.addAll(context.getBeansOfType(CommandLineRunner.class).values());
   // 对runners进行排序
   AnnotationAwareOrderComparator.sort(runners);</p>

<p>   for (Object runner : new LinkedHashSet<Object>(runners)) {
      // 找出Spring容器中ApplicationRunner接口的实现类
      if (runner instanceof ApplicationRunner) {
         callRunner((ApplicationRunner) runner, args);
      }
      // 找出Spring容器中CommandLineRunner接口的实现类
      if (runner instanceof CommandLineRunner) {
         callRunner((CommandLineRunner) runner, args);
      }
   }
}
```
这样run方法执行完成之后。Spring容器也已经初始化完成，各种监听器和初始化器也做了相应的工作。</p>

<h2>配置自动导入</h2>

<pre><code>@Target({ElementType.TYPE})
@Retention(RetentionPolicy.RUNTIME)
@Documented
@Inherited
@AutoConfigurationPackage
@Import({EnableAutoConfigurationImportSelector.class})
public @interface EnableAutoConfiguration {
    String ENABLED_OVERRIDE_PROPERTY = "spring.boot.enableautoconfiguration";

    Class&lt;?&gt;[] exclude() default {};

    String[] excludeName() default {};
}
</code></pre>

<p>主要看EnableAutoConfigurationImportSelector这个类，这个类会导入spring boot中的一个配置文件，方法如下：
```
 protected List<String> getCandidateConfigurations(AnnotationMetadata metadata,
            AnnotationAttributes attributes) {
        List<String> configurations = SpringFactoriesLoader.loadFactoryNames(
                getSpringFactoriesLoaderFactoryClass(), getBeanClassLoader());
        Assert.notEmpty(configurations,
                &ldquo;No auto configuration classes found in META-INF/spring.factories. If you &rdquo;
                        + &ldquo;are using a custom packaging, make sure that file is correct.&rdquo;);
        return configurations;
 }</p>

<pre><code>这个方法会导入spring-boot-autoconfigure包下META-INF/spring.factories配置文件spring.factories


&gt;Spring Boot 内部提供了很多自动化配置的类，例如，
RedisAutoConfiguration 、MongoRepositoriesAutoConfiguration 、ElasticsearchAutoConfiguration ，
这些自动化配置的类会判断 classpath 中是否存在自己需要的那个类，如果存在则会自动配置相关的配置，否则就不会自动配置，
因此，开发者在 Maven 的 pom 文件中添加相关依赖后，这些依赖就会下载很多 jar 包到 classpath 中，有了这些 lib 就会触发自动化配置，
所以，我们就能很便捷地使用对于的模块功能了。

我们看一下自动加载的配置
</code></pre>

<h1>Initializers</h1>

<p>org.springframework.context.ApplicationContextInitializer=\
org.springframework.boot.autoconfigure.logging.AutoConfigurationReportLoggingInitializer</p>

<h1>Application Listeners</h1>

<p>org.springframework.context.ApplicationListener=\
org.springframework.boot.autoconfigure.BackgroundPreinitializer</p>

<h1>Auto Configure</h1>

<p>org.springframework.boot.autoconfigure.EnableAutoConfiguration=\
org.springframework.boot.autoconfigure.admin.SpringApplicationAdminJmxAutoConfiguration,\
org.springframework.boot.autoconfigure.aop.AopAutoConfiguration,\
org.springframework.boot.autoconfigure.amqp.RabbitAutoConfiguration,\
org.springframework.boot.autoconfigure.MessageSourceAutoConfiguration,\
org.springframework.boot.autoconfigure.PropertyPlaceholderAutoConfiguration,\
org.springframework.boot.autoconfigure.batch.BatchAutoConfiguration,\
org.springframework.boot.autoconfigure.cache.CacheAutoConfiguration,\
org.springframework.boot.autoconfigure.cassandra.CassandraAutoConfiguration,\
org.springframework.boot.autoconfigure.cloud.CloudAutoConfiguration,\
org.springframework.boot.autoconfigure.context.ConfigurationPropertiesAutoConfiguration,\
org.springframework.boot.autoconfigure.dao.PersistenceExceptionTranslationAutoConfiguration,\
org.springframework.boot.autoconfigure.data.cassandra.CassandraDataAutoConfiguration,\
org.springframework.boot.autoconfigure.data.cassandra.CassandraRepositoriesAutoConfiguration,\
org.springframework.boot.autoconfigure.data.elasticsearch.ElasticsearchAutoConfiguration,\
org.springframework.boot.autoconfigure.data.elasticsearch.ElasticsearchDataAutoConfiguration,\
org.springframework.boot.autoconfigure.data.elasticsearch.ElasticsearchRepositoriesAutoConfiguration,\
org.springframework.boot.autoconfigure.data.jpa.JpaRepositoriesAutoConfiguration,\
org.springframework.boot.autoconfigure.data.mongo.MongoDataAutoConfiguration,\
org.springframework.boot.autoconfigure.data.mongo.MongoRepositoriesAutoConfiguration,\
org.springframework.boot.autoconfigure.data.solr.SolrRepositoriesAutoConfiguration,\
org.springframework.boot.autoconfigure.data.redis.RedisAutoConfiguration,\
org.springframework.boot.autoconfigure.data.rest.RepositoryRestMvcAutoConfiguration,\
org.springframework.boot.autoconfigure.data.web.SpringDataWebAutoConfiguration,\
org.springframework.boot.autoconfigure.freemarker.FreeMarkerAutoConfiguration,\
org.springframework.boot.autoconfigure.gson.GsonAutoConfiguration,\
org.springframework.boot.autoconfigure.h2.H2ConsoleAutoConfiguration,\
org.springframework.boot.autoconfigure.hateoas.HypermediaAutoConfiguration,\
org.springframework.boot.autoconfigure.hazelcast.HazelcastAutoConfiguration,\
org.springframework.boot.autoconfigure.hazelcast.HazelcastJpaDependencyAutoConfiguration,\
org.springframework.boot.autoconfigure.integration.IntegrationAutoConfiguration,\
org.springframework.boot.autoconfigure.jackson.JacksonAutoConfiguration,\
org.springframework.boot.autoconfigure.jdbc.DataSourceAutoConfiguration,\
org.springframework.boot.autoconfigure.jdbc.JndiDataSourceAutoConfiguration,\
org.springframework.boot.autoconfigure.jdbc.XADataSourceAutoConfiguration,\
org.springframework.boot.autoconfigure.jdbc.DataSourceTransactionManagerAutoConfiguration,\
org.springframework.boot.autoconfigure.jms.JmsAutoConfiguration,\
org.springframework.boot.autoconfigure.jmx.JmxAutoConfiguration,\
org.springframework.boot.autoconfigure.jms.JndiConnectionFactoryAutoConfiguration,\
org.springframework.boot.autoconfigure.jms.activemq.ActiveMQAutoConfiguration,\
org.springframework.boot.autoconfigure.jms.artemis.ArtemisAutoConfiguration,\
org.springframework.boot.autoconfigure.jms.hornetq.HornetQAutoConfiguration,\
org.springframework.boot.autoconfigure.flyway.FlywayAutoConfiguration,\
org.springframework.boot.autoconfigure.groovy.template.GroovyTemplateAutoConfiguration,\
org.springframework.boot.autoconfigure.jersey.JerseyAutoConfiguration,\
org.springframework.boot.autoconfigure.jooq.JooqAutoConfiguration,\
org.springframework.boot.autoconfigure.liquibase.LiquibaseAutoConfiguration,\
org.springframework.boot.autoconfigure.mail.MailSenderAutoConfiguration,\
org.springframework.boot.autoconfigure.mail.MailSenderValidatorAutoConfiguration,\
org.springframework.boot.autoconfigure.mobile.DeviceResolverAutoConfiguration,\
org.springframework.boot.autoconfigure.mobile.DeviceDelegatingViewResolverAutoConfiguration,\
org.springframework.boot.autoconfigure.mobile.SitePreferenceAutoConfiguration,\
org.springframework.boot.autoconfigure.mongo.embedded.EmbeddedMongoAutoConfiguration,\
org.springframework.boot.autoconfigure.mongo.MongoAutoConfiguration,\
org.springframework.boot.autoconfigure.mustache.MustacheAutoConfiguration,\
org.springframework.boot.autoconfigure.orm.jpa.HibernateJpaAutoConfiguration,\
org.springframework.boot.autoconfigure.reactor.ReactorAutoConfiguration,\
org.springframework.boot.autoconfigure.security.SecurityAutoConfiguration,\
org.springframework.boot.autoconfigure.security.SecurityFilterAutoConfiguration,\
org.springframework.boot.autoconfigure.security.FallbackWebSecurityAutoConfiguration,\
org.springframework.boot.autoconfigure.security.oauth2.OAuth2AutoConfiguration,\
org.springframework.boot.autoconfigure.sendgrid.SendGridAutoConfiguration,\
org.springframework.boot.autoconfigure.session.SessionAutoConfiguration,\
org.springframework.boot.autoconfigure.social.SocialWebAutoConfiguration,\
org.springframework.boot.autoconfigure.social.FacebookAutoConfiguration,\
org.springframework.boot.autoconfigure.social.LinkedInAutoConfiguration,\
org.springframework.boot.autoconfigure.social.TwitterAutoConfiguration,\
org.springframework.boot.autoconfigure.solr.SolrAutoConfiguration,\
org.springframework.boot.autoconfigure.velocity.VelocityAutoConfiguration,\
org.springframework.boot.autoconfigure.thymeleaf.ThymeleafAutoConfiguration,\
org.springframework.boot.autoconfigure.transaction.TransactionAutoConfiguration,\
org.springframework.boot.autoconfigure.transaction.jta.JtaAutoConfiguration,\
org.springframework.boot.autoconfigure.web.DispatcherServletAutoConfiguration,\
org.springframework.boot.autoconfigure.web.EmbeddedServletContainerAutoConfiguration,\
org.springframework.boot.autoconfigure.web.ErrorMvcAutoConfiguration,\
org.springframework.boot.autoconfigure.web.HttpEncodingAutoConfiguration,\
org.springframework.boot.autoconfigure.web.HttpMessageConvertersAutoConfiguration,\
org.springframework.boot.autoconfigure.web.MultipartAutoConfiguration,\
org.springframework.boot.autoconfigure.web.ServerPropertiesAutoConfiguration,\
org.springframework.boot.autoconfigure.web.WebMvcAutoConfiguration,\
org.springframework.boot.autoconfigure.websocket.WebSocketAutoConfiguration,\
org.springframework.boot.autoconfigure.websocket.WebSocketMessagingAutoConfiguration</p>

<h1>Template availability providers</h1>

<p>org.springframework.boot.autoconfigure.template.TemplateAvailabilityProvider=\
org.springframework.boot.autoconfigure.freemarker.FreeMarkerTemplateAvailabilityProvider,\
org.springframework.boot.autoconfigure.mustache.MustacheTemplateAvailabilityProvider,\
org.springframework.boot.autoconfigure.groovy.template.GroovyTemplateAvailabilityProvider,\
org.springframework.boot.autoconfigure.thymeleaf.ThymeleafTemplateAvailabilityProvider,\
org.springframework.boot.autoconfigure.velocity.VelocityTemplateAvailabilityProvider,\
org.springframework.boot.autoconfigure.web.JspTemplateAvailabilityProvider
<code>
我们来看如何自动加载MongoAutoConfiguration
</code>
@Configuration
@ConditionalOnClass(MongoClient.class)
@EnableConfigurationProperties(MongoProperties.class)
@ConditionalOnMissingBean(type = &ldquo;org.springframework.data.mongodb.MongoDbFactory&rdquo;)
public class MongoAutoConfiguration {</p>

<p>   private final MongoProperties properties;</p>

<p>   private final MongoClientOptions options;</p>

<p>   private final Environment environment;</p>

<p>   private MongoClient mongo;
&hellip;
```
@ConditionalOnClass(MongoClient.class)
当我们的Jar依赖也就是有我们的环境中存在MongoClient.class,才会创建这个Bean；
其中ConditionalOnClass中依赖@Conditional(OnClassCondition.class)条件，判断是否加载。</p>

<h3>参考</h3>

<p><a href="http://www.imooc.com/article/15432">Spring Boot起步依赖源码分析</a><br/>
<a href="https://fangjian0423.github.io/2017/04/30/springboot-startup-analysis/">SpringBoot源码分析之SpringBoot的启动过程</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[SpringBoot配置读取与加载的几种方式]]></title>
    <link href="http://lvzwq.github.io/blog/2017/07/01/springbootyu-jia-zai/"/>
    <updated>2017-07-01T23:14:32+08:00</updated>
    <id>http://lvzwq.github.io/blog/2017/07/01/springbootyu-jia-zai</id>
    <content type="html"><![CDATA[<blockquote><p>SpringBoot 简化了配置，将原来大量使用xml的配置使用Spring config的方式来是实现，这种方式看上去比xml更加简洁，更好理解。</p></blockquote>

<!-- more -->


<h3>SpringBoot 配置读取</h3>

<p>SpringBoot应用默认读取的应用配置是在application.properties或者application.yml文件中</p>

<pre><code>mq.consumer.topic=binlog.unionbusiness.UnionCommodity
mq.consumer.groupId=ad.cps.commission
mq.consumer.address=mq.keeper.service.xxx.org
mq.consumer.batchSize=20
mq.consumer.timeOut=2000

# mq Consumer 
mq.asyn.topic=binlog.unionbusiness.UnionAsynEffectOps
mq.asyn.groupId=unionads.cps.asyneffect
mq.asyn.address=mq.keeper.service.xxx.org
mq.asyn.batchSize=10
mq.asyn.timeOut=2000

# mq Producer
mq.producer.topic=ad.cpscommission.tradeitemid
mq.producer.groupId=ad.cps.commission
mq.producer.address=mq.keeper.service.xxx.org
</code></pre>

<p>读取的方式有很多种，第一种通过直接通过<code>@ConfigurationProperties</code>注解来读取配置</p>

<pre><code class="java">@Slf4j
@Data
@ConfigurationProperties(prefix = "mq.producer")
@Component
public class CorgiProducer implements InitializingBean, DisposableBean{

    private String topic;
    private String groupId;
    private String address;

    private static Producer producer;

...
}
</code></pre>

<p>另外一种，通过SpringMVC中<code>@Value("${xxx}")</code>注解的方式来获取属性文件中的值
```java
@Data
@Component
public class Config {</p>

<pre><code>@Value("${mq.consumer.groupId}")
private String groupId;

@Value("${mq.consumer.topic}")
private String topic;

@Value("${mq.consumer.address}")
private String address;

@Value("${mq.consumer.batchSize}")
private int batchSize;

@Value("${mq.consumer.timeOut}")
private long timeOut;
</code></pre>

<p>&hellip;
}
```</p>

<p>通过@Bean结合@ConfigurationProperties的方式可以配置相同类的2个不同实例，如配置2个数据源。
```java
@Bean(name = &ldquo;defaultConfig&rdquo;)
@ConfigurationProperties(prefix = &ldquo;mq.consumer&rdquo;)
public CorgiConfig defaultCorgiConfig() {
    return new CorgiConfig();
}</p>

<p>@Bean(name = &ldquo;asynConfig&rdquo;)
@ConfigurationProperties(prefix = &ldquo;mq.asyn&rdquo;)
public CorgiConfig asynCorgiConfig() {
    return new CorgiConfig();
}
```</p>
]]></content>
  </entry>
  
</feed>
